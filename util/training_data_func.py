"""
this module defines all available training functions for generating the training data set
All training function will produce a target value between 0 and 1
"""
from math import exp, sin
from random import uniform
from net.structure import Net_structure
from net.cost import cost_dict
from net.conf import activation_dict
from numpy import *
from functools import reduce
from logf.printf import *

import pdb

_OP_SIZE_ERR = 'not currently support more than 1 output for {}'

def trainingFunc(funcName, input_size, output_size):
    """
    first class function: return a closure of the actual training function

    argument:
        funcName        the description of how the training function should behave
    return:
        the actual training function
    """
    attr_list = ['x{}'.format(i) for i in range(input_size)]
    attr_list += ['y{}'.format(i) for i in range(output_size)]

    if funcName == "sigmoid":
        if output_size > 1:
            printf(_OP_SIZE_ERR, funcName, type='ERROR')
            return
        def sigmoid(xList, output_range):
            """
            simple sigmoid function:
                most suitable for neuron of sigmoid activation
                can be treated as baseline
            """
            op_avg = (output_range[0] + output_range[1])/2
            op_rag = (output_range[1] - output_range[0])
            xAvg = reduce(lambda x1, x2: x1+x2, xList) / len(xList)
            return xList + [op_rag * (1 / (1 + exp(-xAvg) - 0.5)) + op_avg] + [xAvg]
        attr_list += ['xAvg']
        return sigmoid, attr_list
    elif funcName == 'lin':
        if output_size > 1:
            printf(_OP_SIZE_ERR, funcName, type='ERROR')
            return
        def lin(xList, output_range):
            assert len(xList) >= 1
            x_lin = reduce(lambda x1, x2: xList.index(x1)*x1 + xList.index(x2)*x2, xList)
            return xList + [4 * x_lin] + [x_lin]
        attr_list += ['xLin']
        return lin, attr_list
    elif funcName == "sin":
        """
        simple sin function
        """
        if output_size > 1:
            printf(_OP_SIZE_ERR, funcName, type='ERROR')
            return
        def sine(xList, output_range):
            assert len(xList) >= 1
            op_avg = (output_range[0] + output_range[1])/2
            op_rag = (output_range[1] - output_range[0])
            sinAvg = reduce(lambda x1, x2: x1 + x2, xList) / len(xList)
            return xList + [op_rag*sin(sinAvg) + op_avg] + [sinAvg]
        attr_list += ['xAvg']
        return sine, attr_list
    elif funcName == "random":
        def rand(xList, output_range):
            return xList + [uniform(output_range[0], output_range[1])]
        return rand, attr_list
    elif funcName == "ann":
        """
        output is generated by the ANN,
        and the data is intended to be learned by ANN in return
        """
        def forwardANN(xList, struct, activ_list, cost_type):
            net = Net_structure(struct, [activation_dict[n] for n in activ_list], cost_dict[cost_type])
            w_list = []
            b_list = []
            for l in range(len(struct) - 1):
                w_list += [(array(range(struct[l]*struct[l+1])).reshape(struct[l], struct[l+1]) + float(l)) / 100.]
                b_list += [(array(range(struct[l+1])) - float(l)) / 100.]

            net.set_w_b(w_list, b_list)
            return xList + list(net.net_act_forward(array(xList)))
        return forwardANN, attr_list

